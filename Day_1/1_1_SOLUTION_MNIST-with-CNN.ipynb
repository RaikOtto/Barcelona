{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### switch off deprecation and future warnings\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    return [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "\n",
    "# Test whether the GPU has been setup correctly, if correct, ['/device:GPU:0'] will be printed\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "#### INIT WGTS\n",
    "\n",
    "#### INIT BIAS\n",
    "\n",
    "#### CONV2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to help intialize random weights for fully connected or convolutional layers, we leave the shape attribute as a parameter for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as init_weights, but for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **2D convolution** using builtin conv2d from TF. From those docs:\n",
    "\n",
    "Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
    "\n",
    "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "and a filter / kernel tensor of shape\n",
    "`[filter_height, filter_width, in_channels, out_channels]`, this op\n",
    "performs the following:\n",
    "\n",
    "1. Flattens the filter to a 2-D matrix with shape\n",
    "   `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "2. Extracts image patches from the input tensor to form a *virtual*\n",
    "   tensor of shape `[batch, out_height, out_width,\n",
    "   filter_height * filter_width * in_channels]`.\n",
    "3. For each patch, right-multiplies the filter matrix and the image patch\n",
    "   vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    # x --> [batch, H, W, Channels]\n",
    "    # W --> [filter H, filter W, Channels IN, Channel OUT]\n",
    "    # Using convenience function conv2d pass in the tensors, stride one \n",
    "    # in all directions\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **max pooling layer**, again using built in TF functions:\n",
    "\n",
    "Performs the max pooling on the input.\n",
    "\n",
    "    Args:\n",
    "      value: A 4-D `Tensor` with shape `[batch of images, height, width, channels]` and\n",
    "        type `tf.float32`.\n",
    "      ksize: A list of ints that has length >= 4.  The size of the window for\n",
    "        each dimension of the input tensor.\n",
    "      strides: A list of ints that has length >= 4.  The stride of the sliding\n",
    "        window for each dimension of the input tensor.\n",
    "      padding: A string, either `'VALID'` or `'SAME'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    # x --> [batch, h, w, channels], a 4D Tensor\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], # we do pooling along the height and width\n",
    "                          strides=[1, 2, 2, 1], # Same for strides\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So again we're only really concerned as far as the pooling along in individual images height and width\n",
    "which is why we're getting these images of 1 2 2 1 and 1 2 2 1.\n",
    "\n",
    "So now we have our convenience functions that basically already set these parameters for us that we\n",
    "don't need to provide them every time.\n",
    "\n",
    "\n",
    "**Using the conv2d function**, we'll return an actual convolutional layer here that uses an ReLu activation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we're going to create two functions where we actually\n",
    "create the layers.\n",
    "So the first one is going to be the convolutional air.\n",
    "So this function in fact we'll just call it convolutional layer\n",
    "is going to \n",
    "take some input X and then the shape parameter so we'll create\n",
    "the weights by asking in weights with the shape and the biases \n",
    "are just going to run along the third dimension. So I'll say it\n",
    "biases and then we're just going to pass \n",
    "in shape three here.I'm going to use a rectified linear unit as \n",
    "the activation function pass in the to the convolution of input X \n",
    "with those weights Plus biases\n",
    "\"\"\"\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a normal fully connected layer\n",
    "\n",
    "**Narrative**:\n",
    "So we'll make this function say normal full layer. And this is going to take in some input layer of a size and we'll say the input size is equal to the integer of the input layer. And we want to get the shape of the index one they mention will say w initialize the weights and then we're going to pass pass in input size by size to create that layer and then we'll say B = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):  #FCN\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have two functions one creates a convolutional air one creates a normal fully connected layer.\n",
    "So it's time to actually build out multiple layers along with the placeholders do a loss function do\n",
    "an optimizer initialize the variables and run the session.\n",
    "\n",
    "\n",
    "\n",
    "**What is the hardest part?**\n",
    "I would say the hardest part of all of this is keeping in mind your dimensions.\n",
    "Once you do this multiple times if image sets you start to get pretty.\n",
    "So this idea of these for them actions just across the board you have your batch your height your with\n",
    "your channels but in the very beginning it can be hard to keep track or just try to visualize these\n",
    "kind of for the tensors floating around in the layers so it definitely takes a lot of practice as a\n",
    "quick note to kind of understand these dimensions and have them be intuitive.\n",
    "It's definitely not intuitive at first.\n",
    "\n",
    "## Next\n",
    "\n",
    "now it's go ahead and start building out\n",
    "our **CNN**\n",
    "\n",
    "\n",
    "### Placeholders\n",
    "\n",
    "\n",
    "So the first thing we're going to do here is create our placeholders.\n",
    "So we have X is going to be a placeholder.\n",
    "\n",
    "his is our actual data so I'll say to 32 and we'll see the shape we'll say none because that's the\n",
    "size of that batch.\n",
    "\n",
    "And then 784 because that's how many pixels are in the data. So that's 28 times 28.\n",
    "\n",
    "Then we have y_true. These are the y true labels remember it's one encoded. Which means when I say to flip 32 I'll pass in the shape as none because it's again going to be the batch size and then 10 because it's 0 through 9 because of 1-hot encoded.\n",
    "\n",
    "So those are my placeholders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So we have X is going to be a placeholder.\n",
    "This is our actual data so I'll say to 32 and we'll see \n",
    "the shape we'll say none because that's the\n",
    "size of that batch.\n",
    "\n",
    "And then 784 because that's how many pixels are in the data.\n",
    "So that's 28 times 28.\n",
    "\n",
    "Then we have y_true. These are the y true labels remember\n",
    "it's one hot encoded. \n",
    "Which means when I say to flip 32 I'll pass in the shape as\n",
    "none because it's again \n",
    "going to be the batch size and then 10 because \n",
    "it's 0 through 9 because of 1-hot encoded.\n",
    "So those are my placeholders.\n",
    "\"\"\"\n",
    "x = tf.placeholder(tf.float32,shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10])\n",
    "# I only use those for the feed dictionaries and \n",
    "#now it's time to actually create the layers\n",
    "# so the first one we're going to say is the image layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "So why am I doing this because I want to reshape this flattened out array of 784 into the image again.\n",
    "So 28 by 28. That's the height and width.\n",
    "\n",
    "**Tip**: Do you know why we do -1\n",
    "\n",
    "Answer: It means, that the size of the dimension, for which you passed -1, is being inferred. Thus,\n",
    "A.reshape(-1, 28*28) means, \"reshape A so that its second dimension has a size of 28*28 and calculate the correct size of the first dimension\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape\n",
    "# So why am I doing this because I want to reshape \n",
    "# this flattened out array into the image again.\n",
    "# So 28 by 28 That's the height and width.\n",
    "# I remember this one. It's just greyscale. \n",
    "# There's only one color channel there. So now that's my image.\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, used 5by5 in video,\n",
    "# you can play around with the filter size\n",
    "# You can change the 32 output, that essentially \n",
    "#represents the amount of filters used\n",
    "# You need to pass in 32 to the next input though, \n",
    "#the 1 comes from the original input of \n",
    "# a single image.\n",
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a 6by6 filter here, used 5by5 in video, \n",
    "# you can play around with the filter size\n",
    "# You can actually change the 64 output if you want,\n",
    "# you can think of that as a representation\n",
    "# of the amount of 6by6 filters used.\n",
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why 7 by 7 image? Because we did 2 pooling layers, so (28/2)/2 = 7\n",
    "# 64 then just comes from the output of the previous Convolution\n",
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THE PLACEHOLDER HERE!\n",
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "So let's start for a last function we'll use cross entropy to be our loss function and we essentially just use the built in functions that are already TF for us so we say reduce mean to take an average and we'll say soft Max cross entropy and we're going to say that the labels is equal to y true which will be provided by our dictionary later on and then we'll say logits=y_pred and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "So our optimizer, we're going to go ahead and use an adam optimizer say Adam optimizer and then we'll say the learning rates is 0.001 and then our trainer is just going to be for this optimizer to minimize our loss which in our case is the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session\n",
    "\n",
    "`sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})`\n",
    "\n",
    "So remember that we actually have three placeholders. We have the two classic ones which is just x and y. So we'll say X is batch x and y true is that y. And then we have the hold probability because remember we are designing that dropout layer appear. We have this whole probability which is a placeholder and that basically is the probability that a neuron is held during dropout. So during training we'll go ahead and say 50 percent. So each near on has a 50 percent chance of being held essentially randomly dropping out half our neurons.\n",
    "\n",
    "```python\n",
    "if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
    "            print('\\n')\n",
    "```\n",
    "Every 100th step we are going to do something:\n",
    "\n",
    "- Report back our accuracy on the test set.\n",
    "- We did the same for our MLP test (OK so we have our matches remember that's a list of booleans So we want to cast it into a list of floats and then take the average.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "steps = 5000\n",
    "\n",
    "# Creates a session with log_device_placement set to True.\n",
    "config = tf.ConfigProto(log_device_placement = True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "\n",
    "session = tf.Session( config = config )\n",
    "\n",
    "with session as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x , batch_y = mnist.train.next_batch(50)\n",
    "        # Grabbing from the next batch\n",
    "        \n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "        # note: we have 3 placeholders, remmb\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:mnist.test.images,\n",
    "                                          y_true:mnist.test.labels,\n",
    "                                          hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweet stuff!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
